{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Theory in the world of Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entropy of a random variable is the average level of uncertainty associated with the variables potential state\\\n",
    "The measure of the expected amount of information to describe the state of the variable condisering the distribution of probabilities across all potential states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from math import log2\n",
    "\n",
    "def entropy(probabilities: List[float]) -> float:\n",
    "    \n",
    "    H = -sum(p * log2(p) for p in probabilities if p > 0)\n",
    "    \n",
    "    return H\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "probabilities: List[float] = [0.25, 0.25, 0.25,0.25]\n",
    "\n",
    "try:\n",
    "    sum(probabilities) == 1\n",
    "except:\n",
    "    print(\"Error: The probabilities are not valid\")\n",
    "    \n",
    "print(entropy(probabilities=probabilities))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shanon Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the measure of the average amount of information contained in a message\\\n",
    "It quantifies the unpredictability of info content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of the unique characters in the message:\n",
      "(' ', 1)\n",
      "('H', 1)\n",
      "('d', 1)\n",
      "('e', 1)\n",
      "('l', 3)\n",
      "('o', 2)\n",
      "('r', 1)\n",
      "('w', 1)\n",
      "Shannon entropy of 'Hello world': 2.85 bits\n",
      "Count of the unique characters in the message:\n",
      "('0', 3)\n",
      "('1', 5)\n",
      "Shannon entropy of 'Hello world': 0.95 bits\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import Union\n",
    "\n",
    "def shannon_entropy(data: Union[List[Union[float, str, int]], str])->float:\n",
    "    \n",
    "    chars, counts = np.unique(data, return_counts=True)\n",
    "\n",
    "    # Count of the unique characters in the message\n",
    "    char_counts = list(zip(chars, counts))\n",
    "    print(\"Count of the unique characters in the message:\")\n",
    "    for char, count in char_counts:\n",
    "        print(f\"('{char}', {count})\")\n",
    "\n",
    "    # Compute Shannon entropy\n",
    "    probabilities = counts / len(data)\n",
    "    return -np.sum(probabilities * np.log2(probabilities))\n",
    "\n",
    "# Example: Calculate Shannon entropy for a text message\n",
    "message1 = \"Hello world\"\n",
    "# Example: Calculate Shannon entropy for a boolean message\n",
    "message2 = [1,0,1,1,0,1,1,0]\n",
    "\n",
    "print(f\"Shannon entropy of '{message1}': {shannon_entropy(list(message1)):.2f} bits\")\n",
    "print(f\"Shannon entropy of '{message1}': {shannon_entropy(list(message2)):.2f} bits\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy in Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since entropy is the measure of uncertainty and the objective of ML is to minimize the uncertainty the two are linked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the measure of the reduction in Entropy achieved by splitting a dataset according to a particular feature (this is used in tree algorithms to select the features)\\\n",
    "This is the amount of information a feature can provide about a class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:\\\n",
    "We have a dataset with cancerous (C) and non cancerous cells (NC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Samples  Mutation 1  Mutation 2  Mutation 3  Mutation 4\n",
      "0      C1           1           1           1           0\n",
      "1      C2           1           1           0           1\n",
      "2      C3           1           0           1           1\n",
      "3      C4           0           1           1           0\n",
      "4     NC1           0           0           0           0\n",
      "5     NC2           0           1           0           0\n",
      "6     NC3           1           1           0           0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "\n",
    "# Data for the DataFrame\n",
    "data: Dict[str, Union[str, float]] = {\n",
    "    'Samples': ['C1', 'C2', 'C3', 'C4', 'NC1', 'NC2', 'NC3'],\n",
    "    'Mutation 1': [1, 1, 1, 0, 0, 0, 1],\n",
    "    'Mutation 2': [1, 1, 0, 1, 0, 1, 1],\n",
    "    'Mutation 3': [1, 0, 1, 1, 0, 0, 0],\n",
    "    'Mutation 4': [0, 1, 1, 0, 0, 0, 0]\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data, index=None)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a very simple decision tree with 1 parent node which is highly impute with all the features and 2 pure child nodes one with just the cancerous cells and the other one all the non cancerous cells\\\n",
    "Then we wanna know how to split the data in order to classify the future nodes the best we can (which means than the node childs 1 and 2 must be as pure a possible)\n",
    "\n",
    " **Parent Node:** The parent node is represented with its high impurity (4C + 3NC)\n",
    "* **Child Nodes Left:** Pure node with only Cancerous cells (P=4/7)\n",
    "* **Child Nodes Right:** Pure node with only Non Cancerous cells (P=3/7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities of the cancerous cells for Mutation 1: 0.5714285714285714\n",
      "Probabilities of the cancerous cells for Mutation 1: 0.42857142857142855\n",
      "0.9852281360342516\n"
     ]
    }
   ],
   "source": [
    "# Definition of the variables to calculate the entropy\n",
    "sum_elements_mut1: int = df['Mutation 1'].shape[0]\n",
    "sum_zeros_in_mut1: int = (df['Mutation 1'] == 0).sum()\n",
    "sum_ones_in_mut1: int = (df['Mutation 1'] == 1).sum()\n",
    "\n",
    "prob_NC_mut1: float  = sum_zeros_in_mut1 / sum_elements_mut1\n",
    "prob_C_mut1: float = sum_ones_in_mut1 / sum_elements_mut1\n",
    "\n",
    "# Display the probabilities for the cancerous and non cancerous cells\n",
    "print(f\"Probabilities of the cancerous cells for {df['Mutation 1'].name}: {prob_C_mut1}\")\n",
    "print(f\"Probabilities of the cancerous cells for {df['Mutation 1'].name}: {prob_NC_mut1}\")\n",
    "\n",
    "try:\n",
    "    prob_C_mut1 + prob_NC_mut1 == 1.0\n",
    "except:\n",
    "    print(\"Error: The probabilities do not add up to 1\")\n",
    "    \n",
    "# Calculate the entropy of the parent node\n",
    "\n",
    "feature_nodes_mut1: List[float] = [prob_C_mut1, prob_NC_mut1]\n",
    "H_parent_node_mut1 = entropy(feature_nodes_mut1)\n",
    "print(H_parent_node_mut1) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_env_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
